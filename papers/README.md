# Downloaded Papers

1. [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](2201.11903_chain_of_thought_prompting.pdf)
   - Authors: Jason Wei, Xuezhi Wang, Dale Schuurmans, et al.
   - Year: 2022 (arXiv:2201.11903)
   - Why relevant: Introduces CoT prompting as baseline; foundational reference for any story-like CoT extensions.

2. [Self-Consistency Improves Chain of Thought Reasoning in Language Models](2203.11171_self_consistency_cot.pdf)
   - Authors: Xuezhi Wang, Jason Wei, Dale Schuurmans, et al.
   - Year: 2022 (arXiv:2203.11171)
   - Why relevant: Sampling-and-voting over diverse CoTs; useful comparator for structured/story CoT decoding.

3. [Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models](2305.04091_plan_and_solve_prompting.pdf)
   - Authors: Lei Wang, Baolin Peng, Hoifung Poon, et al.
   - Year: 2023 (arXiv:2305.04091)
   - Why relevant: Separates planning from solving; parallels story outlines before details.

4. [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](2305.10601_tree_of_thoughts.pdf)
   - Authors: Shunyu Yao, Dian Yu, Jeffrey Zhao, et al.
   - Year: 2023 (arXiv:2305.10601)
   - Why relevant: Search over thought sequences; relates to structured narrative CoTs.

5. [Graph of Thoughts: Solving Elaborate Problems with Large Language Models](2407.06070_graph_of_thoughts.pdf)
   - Authors: Mateusz Besta, Shunyu Yao, Torsten Hoefler, et al.
   - Year: 2024 (arXiv:2407.06070)
   - Why relevant: Generalizes CoT to graph-structured reasoning pathways; connects to story weaving.

6. [Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks](2308.08708_program_of_thoughts.pdf)
   - Authors: Wenhu Chen, Xiang Lorraine Li, Xinyi Wang, et al.
   - Year: 2023 (arXiv:2308.08708)
   - Why relevant: Formalizes CoTs as programs; contrast to narrative/story CoTs.

7. [Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding](2307.15337_skeleton_of_thought.pdf)
   - Authors: Yilei Yang, et al. (skeleton-of-thought contributors)
   - Year: 2023 (arXiv:2307.15337)
   - Why relevant: Uses outline + fill strategy reminiscent of story scaffolds.
